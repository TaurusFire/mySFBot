{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import retro\n",
    "import time\n",
    "import os\n",
    "from gym import Env\n",
    "from gym.spaces import MultiBinary, Box\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import optuna\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import tensorboard\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#define the environment: observation space, action space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreetFighter(Env):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        #the observation space is a 84x84 box with each value correp to a colour\n",
    "        self.observation_space = Box(low=0, high=255, \n",
    "                                     shape=(84,84,1), dtype=np.uint8)\n",
    "        \n",
    "        #12-long vector where each action corresps to a 0 or a 1\n",
    "        self.action_space = MultiBinary(12)\n",
    "        \n",
    "        #start up an instance of the game\n",
    "        #use restricted actions ensures that only valid button combinations are chosen\n",
    "        self.game = retro.make(game=\"StreetFighterIISpecialChampionEdition-Genesis\",\n",
    "                               use_restricted_actions = retro.Actions.FILTERED)\n",
    "\n",
    "    def preprocess(self, observation):\n",
    "        gray = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (84,84), interpolation= cv2.INTER_CUBIC)\n",
    "        channels = np.reshape(resize, (84,84,1))\n",
    "        return channels\n",
    "    \n",
    "    def step(self,action):\n",
    "        obs, reward, done, info = self.game.step(action)\n",
    "\n",
    "        obs = self.preprocess(obs)\n",
    "\n",
    "        frame_delta = obs - self.previous_frame\n",
    "        self.previous_frame = obs\n",
    "        reward = info['score'] - self.score\n",
    "        self.score = info['score']\n",
    "\n",
    "        return frame_delta, reward, done, info\n",
    "    \n",
    "    def render(self, *args, **kwargs):\n",
    "        self.game.render()\n",
    "        \n",
    "    def reset(self):\n",
    "        # Return the first frame \n",
    "        obs = self.game.reset()\n",
    "        obs = self.preprocess(obs) \n",
    "        self.previous_frame = obs \n",
    "        \n",
    "        # Create a attribute to hold the score delta \n",
    "        self.score = 0 \n",
    "        return obs\n",
    "    \n",
    "    def close(self):\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = './A2Clogs/'\n",
    "OPT_DIR = './A2Copt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objectiveA2C(trial):\n",
    "    return {\n",
    "        'n_steps': trial.suggest_int('n_steps',2048,8192),\n",
    "        'gamma': trial.suggest_float('gamma',0.8,0.9999, log=True),\n",
    "        'learning_rate': trial.suggest_float('learning_rate',1e-6,1e-5, log=True),\n",
    "        'gae_lambda': trial.suggest_float('gae_lambda',0.8,0.99)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_agent(trial):\n",
    "    #try:\n",
    "        model_params = objectiveA2C(trial)\n",
    "\n",
    "        #create environment\n",
    "        env = StreetFighter()\n",
    "        env = Monitor(env, LOG_DIR)\n",
    "        env =  DummyVecEnv([lambda:env])\n",
    "        env = VecFrameStack(env, 4, channels_order='last')\n",
    "        model = A2C('CnnPolicy',env, tensorboard_log=LOG_DIR, verbose=0, **model_params)\n",
    "        print(\"model_made\")\n",
    "        model.learn(total_timesteps=100000)\n",
    "        print(\"model learned\")\n",
    "\n",
    "        mean_reward, __ = evaluate_policy(model, env, n_eval_episodes=5)\n",
    "        env.close()\n",
    "\n",
    "        SAVE_PATH = os.path.join(OPT_DIR, 'trial_{}_best_model'.format(trial.number))\n",
    "        model.save(SAVE_PATH)\n",
    "        \n",
    "        return mean_reward\n",
    "    \n",
    "    #except Exception as e:\n",
    "     #  return -1000\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-12 13:30:15,628] A new study created in memory with name: no-name-8aad12ad-e796-440e-8973-8f6d4433ad0c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_made\n",
      "model learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-12 13:35:12,965] Trial 0 finished with value: 4500.0 and parameters: {'n_steps': 7941, 'gamma': 0.8663412679242408, 'learning_rate': 1.3756970061853513e-06, 'gae_lambda': 0.9095683342511351}. Best is trial 0 with value: 4500.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_made\n",
      "model learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-12 13:41:04,588] Trial 1 finished with value: 18100.0 and parameters: {'n_steps': 5834, 'gamma': 0.9532514222680888, 'learning_rate': 3.8509210607144295e-06, 'gae_lambda': 0.9790912340563886}. Best is trial 1 with value: 18100.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_made\n",
      "model learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-12 13:46:34,858] Trial 2 finished with value: 0.0 and parameters: {'n_steps': 4362, 'gamma': 0.98268551561208, 'learning_rate': 7.127695420229584e-06, 'gae_lambda': 0.8321319788402167}. Best is trial 1 with value: 18100.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_made\n",
      "model learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-12 13:51:30,202] Trial 3 finished with value: 1000.0 and parameters: {'n_steps': 4252, 'gamma': 0.9806151632514849, 'learning_rate': 4.656764298235243e-06, 'gae_lambda': 0.9583989449522734}. Best is trial 1 with value: 18100.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_made\n",
      "model learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-12 13:57:01,079] Trial 4 finished with value: 1900.0 and parameters: {'n_steps': 4149, 'gamma': 0.9531188114863924, 'learning_rate': 5.079551467056385e-06, 'gae_lambda': 0.9886142257354342}. Best is trial 1 with value: 18100.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_made\n",
      "model learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-12 14:02:25,797] Trial 5 finished with value: 1000.0 and parameters: {'n_steps': 5082, 'gamma': 0.9200829751203636, 'learning_rate': 6.068525608623374e-06, 'gae_lambda': 0.8620870837237014}. Best is trial 1 with value: 18100.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_made\n",
      "model learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-12 14:07:59,345] Trial 6 finished with value: 1800.0 and parameters: {'n_steps': 6588, 'gamma': 0.8530801768400269, 'learning_rate': 2.9679885414326437e-06, 'gae_lambda': 0.8528718224668003}. Best is trial 1 with value: 18100.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_made\n",
      "model learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-12 14:13:23,528] Trial 7 finished with value: 200.0 and parameters: {'n_steps': 7167, 'gamma': 0.9900433416017995, 'learning_rate': 8.287108694225938e-06, 'gae_lambda': 0.9137101821077287}. Best is trial 1 with value: 18100.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_made\n",
      "model learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-12 14:18:37,957] Trial 8 finished with value: 4600.0 and parameters: {'n_steps': 2054, 'gamma': 0.9502517312474695, 'learning_rate': 1.303061036066252e-06, 'gae_lambda': 0.9069686611891224}. Best is trial 1 with value: 18100.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_made\n",
      "model learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-12 14:23:48,818] Trial 9 finished with value: 4600.0 and parameters: {'n_steps': 5875, 'gamma': 0.9822658979737727, 'learning_rate': 1.5233019714238133e-06, 'gae_lambda': 0.9434599087519566}. Best is trial 1 with value: 18100.0.\n"
     ]
    }
   ],
   "source": [
    "#create the experiment/study. since returning a positive value, want to maximise the function. \n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_agent, n_trials=10, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params \"\"\"={'n_steps': 5834,\n",
    "  'gamma': 0.9532514222680888,\n",
    "  'learning_rate': 3.8509210607144295e-06,\n",
    "  'gae_lambda': 0.9790912340563886}\"\"\"\n",
    "\n",
    "model_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "5834/64 #=91.15625\n",
    "91*64 #=5824\n",
    "model_params['n_steps'] = 5824"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "model = A2C.load(os.path.join(OPT_DIR, \"trial_1_best_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks are functions that is passed as an argument to another function or method\n",
    "\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = \"./A2Ctrain/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model every 10,000 steps at checkpoint_dir\n",
    "callback = TrainAndLoggingCallback(check_freq=100000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create env with preprocessing\n",
    "\n",
    "env = StreetFighter()\n",
    "env = Monitor(env, LOG_DIR)\n",
    "env = DummyVecEnv([lambda:env])\n",
    "env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7f22e63b9d30>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = A2C('CnnPolicy',env, tensorboard_log=LOG_DIR, verbose=0, **model_params)\n",
    "model.load(os.path.join(OPT_DIR, 'trial_1_best_model.zip'))\n",
    "model.learn(total_timesteps=1000000, callback= callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input the path of the model you want to evaluate\n",
    "model = A2C.load(\"./A2Ctrain/best_model_1000000.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchDisplayException",
     "evalue": "Cannot connect to \"None\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchDisplayException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done: \n\u001b[1;32m      8\u001b[0m     obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m----> 9\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m action \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m obs, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m~/virtualenv/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:282\u001b[0m, in \u001b[0;36mVecEnvWrapper.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenv/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:98\u001b[0m, in \u001b[0;36mDummyVecEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03mGym environment rendering. If there are multiple environments then\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03mthey are tiled together in one image via ``BaseVecEnv.render()``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m:param mode: The rendering type.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrender(mode\u001b[38;5;241m=\u001b[39mmode)\n",
      "File \u001b[0;32m~/virtualenv/lib/python3.8/site-packages/gym/core.py:295\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 40\u001b[0m, in \u001b[0;36mStreetFighter.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenv/lib/python3.8/site-packages/retro/retro_env.py:228\u001b[0m, in \u001b[0;36mRetroEnv.render\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 228\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassic_control\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrendering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleImageViewer\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer \u001b[38;5;241m=\u001b[39m SimpleImageViewer()\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer\u001b[38;5;241m.\u001b[39mimshow(img)\n",
      "File \u001b[0;32m~/virtualenv/lib/python3.8/site-packages/gym/envs/classic_control/rendering.py:27\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    Cannot import pyglet.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyglet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    Error occurred while running `from pyglet.gl import *`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     )\n",
      "File \u001b[0;32m~/virtualenv/lib/python3.8/site-packages/pyglet/gl/__init__.py:232\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_pyglet_doc_run \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyglet.window\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _sys\u001b[38;5;241m.\u001b[39mmodules \u001b[38;5;129;01mand\u001b[39;00m _pyglet\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshadow_window\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# trickery is for circular import\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     _pyglet\u001b[38;5;241m.\u001b[39mgl \u001b[38;5;241m=\u001b[39m _sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;18m__name__\u001b[39m]\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyglet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwindow\u001b[39;00m\n",
      "File \u001b[0;32m~/virtualenv/lib/python3.8/site-packages/pyglet/window/__init__.py:1919\u001b[0m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_pyglet_doc_run:\n\u001b[1;32m   1918\u001b[0m     pyglet\u001b[38;5;241m.\u001b[39mwindow \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;18m__name__\u001b[39m]\n\u001b[0;32m-> 1919\u001b[0m     \u001b[43mgl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_shadow_window\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenv/lib/python3.8/site-packages/pyglet/gl/__init__.py:206\u001b[0m, in \u001b[0;36m_create_shadow_window\u001b[0;34m()\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyglet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwindow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Window\n\u001b[0;32m--> 206\u001b[0m _shadow_window \u001b[38;5;241m=\u001b[39m \u001b[43mWindow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisible\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m _shadow_window\u001b[38;5;241m.\u001b[39mswitch_to()\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyglet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m app\n",
      "File \u001b[0;32m~/virtualenv/lib/python3.8/site-packages/pyglet/window/xlib/__init__.py:171\u001b[0m, in \u001b[0;36mXlibWindow.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_handlers[message] \u001b[38;5;241m=\u001b[39m func\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXlibWindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _can_detect_autorepeat\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_detect_autorepeat \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/virtualenv/lib/python3.8/site-packages/pyglet/window/__init__.py:591\u001b[0m, in \u001b[0;36mBaseWindow.__init__\u001b[0;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, file_drops, display, screen, config, context, mode)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_queue \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m display:\n\u001b[0;32m--> 591\u001b[0m     display \u001b[38;5;241m=\u001b[39m \u001b[43mpyglet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_display\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m screen:\n\u001b[1;32m    594\u001b[0m     screen \u001b[38;5;241m=\u001b[39m display\u001b[38;5;241m.\u001b[39mget_default_screen()\n",
      "File \u001b[0;32m~/virtualenv/lib/python3.8/site-packages/pyglet/canvas/__init__.py:94\u001b[0m, in \u001b[0;36mget_display\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m display\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Otherwise, create a new display and return it.\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenv/lib/python3.8/site-packages/pyglet/canvas/xlib.py:123\u001b[0m, in \u001b[0;36mXlibDisplay.__init__\u001b[0;34m(self, name, x_screen)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_display \u001b[38;5;241m=\u001b[39m xlib\u001b[38;5;241m.\u001b[39mXOpenDisplay(name)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_display:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDisplayException(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot connect to \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n\u001b[1;32m    125\u001b[0m screen_count \u001b[38;5;241m=\u001b[39m xlib\u001b[38;5;241m.\u001b[39mXScreenCount(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_display)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_screen \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m screen_count:\n",
      "\u001b[0;31mNoSuchDisplayException\u001b[0m: Cannot connect to \"None\""
     ]
    }
   ],
   "source": [
    "# Reset game to starting state\n",
    "obs = env.reset()\n",
    "# Set flag to flase. Then predict using the model.\n",
    "done = False\n",
    "for game in range(1): \n",
    "    while not done: \n",
    "        if done: \n",
    "            obs = env.reset()\n",
    "        env.render()\n",
    "        action = model.predict(obs)[0]\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        time.sleep(0.01)\n",
    "        print(reward)\n",
    "\n",
    "#Can also have a separate testing notebook alongside the training notebook \n",
    "# so you can test and train at the same time and check you are headed in the right \n",
    "# direction - so don't need to wait until the end to see if the model is performing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
